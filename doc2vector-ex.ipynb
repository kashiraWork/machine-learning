{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文章のベクトル化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gensimのcorpora, matutilsでベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora,matutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 文章リスト (本来であれば、もとの文章に対して、形態素解析した上で、生成)\n",
    "doclist = [['human', 'interface', 'computer'],\n",
    "            ['survey', 'user', 'computer', 'system'],\n",
    "            ['eps', 'user', 'interface'],\n",
    "            ['system', 'human', 'system', 'eps'],\n",
    "            ['user','time'],\n",
    "            ['trees', 'user'],\n",
    "            ['graph', 'trees'],\n",
    "            ['graph', 'minors', 'minors','trees'],\n",
    "            ['graph', 'minors', 'survey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 辞書生成\n",
    "dct = corpora.Dictionary(doclist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'survey': 3, 'system': 4, 'user': 5, 'eps': 6, 'time': 7, 'trees': 8, 'graph': 9, 'minors': 10}\n",
      "{1: 2, 2: 2, 0: 2, 3: 2, 5: 4, 4: 2, 6: 2, 7: 1, 8: 3, 9: 3, 10: 2}\n"
     ]
    }
   ],
   "source": [
    "print(dct.token2id)\n",
    "print(dct.dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (4, 2), (6, 1)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 文書をBoW表現(ID)と頻度（重み）のセットに変換する。\n",
    "dct.doc2bow(doclist[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matutils.corpus2dense([dct.doc2bow(doclist[0]), dct.doc2bow(doclist[1])], num_terms=len(dct)).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matutils.corpus2dense([dct.doc2bow(doclist[0])], num_terms=len(dct)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# 単文章のベクトル化\n",
    "dense0 = list(matutils.corpus2dense([dct.doc2bow(doclist[0])], num_terms=len(dct)).T[0])\n",
    "print(dense0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), array([1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "# 複数文章の(2つ)のベクトル化\n",
    "dense0_1 = list(matutils.corpus2dense([dct.doc2bow(doclist[0]), dct.doc2bow(doclist[1])], num_terms=len(dct)).T)\n",
    "print(dense0_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#全文章のベクトル化\n",
    "def vec2dense(vec, num_terms):\n",
    "    return list(matutils.corpus2dense([vec], num_terms=num_terms).T[0])\n",
    "data_all  = [vec2dense(dct.doc2bow(doclist[i]),len(dct)) for i in range(len(doclist))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
       " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 2.0],\n",
       " [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## numpyによるベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'human': 3, 'interface': 4, 'computer': 0, 'survey': 6, 'user': 10, 'system': 7, 'eps': 1, 'time': 8, 'trees': 9, 'graph': 2, 'minors': 5}\n",
      "[[1 0 0 1 1 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 1 1 0 0 1]\n",
      " [0 1 0 0 1 0 0 0 0 0 1]\n",
      " [0 1 0 1 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 1 0 0 0 0 0 0 1 0]\n",
      " [0 0 1 0 0 2 0 0 0 1 0]\n",
      " [0 0 1 0 0 1 1 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer()\n",
    "\"\"\"\n",
    "doclist = [['human', 'interface', 'computer'],\n",
    "            ['survey', 'user', 'computer', 'system'],\n",
    "            ['eps', 'user', 'interface'],\n",
    "            ['system', 'human', 'system', 'eps'],\n",
    "            ['user','time'],\n",
    "            ['trees', 'user'],\n",
    "            ['graph', 'trees'],\n",
    "            ['graph', 'minors', 'minors','trees'],\n",
    "            ['graph', 'minors', 'survey']]\n",
    "            \n",
    "\"\"\"\n",
    "\n",
    "bag = count.fit_transform(np.array([\" \".join(doc) for doc in doclist]))\n",
    "print(count.vocabulary_)\n",
    "print(bag.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
